{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB1 - Model Operationalization & Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run the below lab, make sure that you run the Part 3 lab: [Meetup10-Lab-stockdemo.ipynb](Meetup10-Lab-stockdemo.ipynb)\n",
    "\n",
    "In this notebook, we will create the artifacts and scripts to deploy the LSTM model into a webservice on Azure. The artifacts include the model files, and test scripts to validate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /data/anaconda/envs/py36/lib/python3.6/site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from h5py) (1.14.5)\n",
      "Requirement already satisfied: six in /data/anaconda/envs/py36/lib/python3.6/site-packages (from h5py) (1.11.0)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mazureml-contrib-brainwave 0.1.56 requires tensorflow>=1.6, which is not installed.\u001b[0m\n",
      "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-widgets 0.1.74 has requirement azureml-core==0.1.74.*, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-widgets 0.1.74 has requirement azureml-pipeline==0.1.74.*, but you'll have azureml-pipeline 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-widgets 0.1.74 has requirement azureml-telemetry==0.1.74.*, but you'll have azureml-telemetry 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-widgets 0.1.74 has requirement azureml-train-core==0.1.74.*, but you'll have azureml-train-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-automl 0.1.59 has requirement azureml-core==0.1.59, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-automl 0.1.59 has requirement azureml-telemetry==0.1.59, but you'll have azureml-telemetry 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-tensorboard 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-server 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-run 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-brainwave 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-brainwave 0.1.56 has requirement keras==2.1.5, but you'll have keras 2.2.4 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: pandas in /data/anaconda/envs/py36/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already up-to-date: azureml-sdk in /data/anaconda/envs/py36/lib/python3.6/site-packages (1.0.2)\n",
      "Collecting keras==2.1.5\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl\n",
      "Requirement not upgraded as not directly required: numpy>=1.9.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from pandas) (1.14.5)\n",
      "Requirement not upgraded as not directly required: pytz>=2011k in /data/anaconda/envs/py36/lib/python3.6/site-packages (from pandas) (2018.5)\n",
      "Requirement not upgraded as not directly required: python-dateutil>=2.5.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from pandas) (2.7.3)\n",
      "Requirement not upgraded as not directly required: azureml-pipeline==1.0.2.* in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-sdk) (1.0.2)\n",
      "Requirement not upgraded as not directly required: azureml-train==1.0.2.* in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-sdk) (1.0.2)\n",
      "Requirement not upgraded as not directly required: azureml-core==1.0.2.* in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-sdk) (1.0.2)\n",
      "Requirement not upgraded as not directly required: six>=1.9.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from keras==2.1.5) (1.11.0)\n",
      "Requirement not upgraded as not directly required: scipy>=0.14 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from keras==2.1.5) (1.1.0)\n",
      "Requirement not upgraded as not directly required: pyyaml in /data/anaconda/envs/py36/lib/python3.6/site-packages (from keras==2.1.5) (3.13)\n",
      "Requirement not upgraded as not directly required: azureml-pipeline-steps==1.0.2.* in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-pipeline==1.0.2.*->azureml-sdk) (1.0.2)\n",
      "Requirement not upgraded as not directly required: azureml-pipeline-core==1.0.2.* in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-pipeline==1.0.2.*->azureml-sdk) (1.0.2)\n",
      "Requirement not upgraded as not directly required: azureml-train-core==1.0.2.* in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-train==1.0.2.*->azureml-sdk) (1.0.2)\n",
      "Requirement not upgraded as not directly required: pathspec in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (0.5.9)\n",
      "Requirement not upgraded as not directly required: SecretStorage<3.0.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (2.3.1)\n",
      "Requirement not upgraded as not directly required: azure-graphrbac>=0.40.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (0.40.0)\n",
      "Requirement not upgraded as not directly required: azure-mgmt-resource>=1.2.1 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (2.0.0)\n",
      "Requirement not upgraded as not directly required: urllib3<1.24,>=1.23 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (1.23)\n",
      "Requirement not upgraded as not directly required: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (2.3.1)\n",
      "Requirement not upgraded as not directly required: azure-storage-common>=1.1.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (1.3.0)\n",
      "Requirement not upgraded as not directly required: docker in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (3.5.0)\n",
      "Requirement not upgraded as not directly required: azure-mgmt-authorization>=0.40.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (0.50.0)\n",
      "Requirement not upgraded as not directly required: azure-cli-profile>=2.0.26 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (2.1.1)\n",
      "Requirement not upgraded as not directly required: azure-mgmt-storage>=1.5.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (2.0.0)\n",
      "Requirement not upgraded as not directly required: azure-common>=1.1.12 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (1.1.15)\n",
      "Requirement not upgraded as not directly required: ndg-httpsclient in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (0.5.1)\n",
      "Requirement not upgraded as not directly required: requests>=2.19.1 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (2.19.1)\n",
      "Requirement not upgraded as not directly required: azure-storage-blob>=1.1.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (1.3.1)\n",
      "Requirement not upgraded as not directly required: PyJWT in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (1.6.4)\n",
      "Requirement not upgraded as not directly required: backports.tempfile in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (1.0)\n",
      "Requirement not upgraded as not directly required: azure-storage-nspkg>=3.0.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (3.0.0)\n",
      "Requirement not upgraded as not directly required: azure-mgmt-keyvault>=0.40.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (1.1.0)\n",
      "Requirement not upgraded as not directly required: msrest>=0.5.1 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (0.5.5)\n",
      "Requirement not upgraded as not directly required: jsonpickle in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (0.9.6)\n",
      "Requirement not upgraded as not directly required: contextlib2 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (0.5.5)\n",
      "Requirement not upgraded as not directly required: azure-mgmt-containerregistry>=2.0.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (2.2.0)\n",
      "Requirement not upgraded as not directly required: ruamel.yaml<=0.15.51,>=0.15.35 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (0.15.51)\n",
      "Requirement not upgraded as not directly required: azure-cli-core>=2.0.38 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (2.0.45)\n",
      "Requirement not upgraded as not directly required: msrestazure>=0.4.33 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-core==1.0.2.*->azureml-sdk) (0.5.0)\n",
      "Requirement not upgraded as not directly required: certifi in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-pipeline-steps==1.0.2.*->azureml-pipeline==1.0.2.*->azureml-sdk) (2018.8.24)\n",
      "Requirement not upgraded as not directly required: azureml-telemetry==1.0.2.* in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-train-core==1.0.2.*->azureml-train==1.0.2.*->azureml-sdk) (1.0.2)\n",
      "Requirement not upgraded as not directly required: azureml-train-restclients-hyperdrive==1.0.2.* in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-train-core==1.0.2.*->azureml-train==1.0.2.*->azureml-sdk) (1.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement not upgraded as not directly required: azure-nspkg>=2.0.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-graphrbac>=0.40.0->azureml-core==1.0.2.*->azureml-sdk) (2.0.0)\n",
      "Requirement not upgraded as not directly required: azure-mgmt-nspkg>=2.0.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-mgmt-resource>=1.2.1->azureml-core==1.0.2.*->azureml-sdk) (2.0.0)\n",
      "Requirement not upgraded as not directly required: idna>=2.1 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.2.*->azureml-sdk) (2.7)\n",
      "Requirement not upgraded as not directly required: asn1crypto>=0.21.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.2.*->azureml-sdk) (0.24.0)\n",
      "Requirement not upgraded as not directly required: cffi!=1.11.3,>=1.7 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.2.*->azureml-sdk) (1.11.5)\n",
      "Requirement not upgraded as not directly required: websocket-client>=0.32.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from docker->azureml-core==1.0.2.*->azureml-sdk) (0.53.0)\n",
      "Requirement not upgraded as not directly required: docker-pycreds>=0.3.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from docker->azureml-core==1.0.2.*->azureml-sdk) (0.3.0)\n",
      "Requirement not upgraded as not directly required: azure-cli-command-modules-nspkg>=2.0.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-profile>=2.0.26->azureml-core==1.0.2.*->azureml-sdk) (2.0.2)\n",
      "Requirement not upgraded as not directly required: PyOpenSSL in /data/anaconda/envs/py36/lib/python3.6/site-packages (from ndg-httpsclient->azureml-core==1.0.2.*->azureml-sdk) (18.0.0)\n",
      "Requirement not upgraded as not directly required: pyasn1>=0.1.1 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from ndg-httpsclient->azureml-core==1.0.2.*->azureml-sdk) (0.4.4)\n",
      "Requirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core==1.0.2.*->azureml-sdk) (3.0.4)\n",
      "Requirement not upgraded as not directly required: backports.weakref in /data/anaconda/envs/py36/lib/python3.6/site-packages (from backports.tempfile->azureml-core==1.0.2.*->azureml-sdk) (1.0.post1)\n",
      "Requirement not upgraded as not directly required: requests-oauthlib>=0.5.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core==1.0.2.*->azureml-sdk) (1.0.0)\n",
      "Requirement not upgraded as not directly required: isodate>=0.6.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core==1.0.2.*->azureml-sdk) (0.6.0)\n",
      "Requirement not upgraded as not directly required: pygments in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (2.2.0)\n",
      "Requirement not upgraded as not directly required: antlr4-python3-runtime in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (4.7.1)\n",
      "Requirement not upgraded as not directly required: knack==0.4.2 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (0.4.2)\n",
      "Requirement not upgraded as not directly required: colorama>=0.3.9 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (0.3.9)\n",
      "Requirement not upgraded as not directly required: paramiko>=2.0.8 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (2.4.2)\n",
      "Requirement not upgraded as not directly required: jmespath in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (0.9.3)\n",
      "Requirement not upgraded as not directly required: tabulate<=0.8.2,>=0.7.7 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (0.8.2)\n",
      "Requirement not upgraded as not directly required: wheel==0.30.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (0.30.0)\n",
      "Requirement not upgraded as not directly required: pip in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (10.0.1)\n",
      "Requirement not upgraded as not directly required: humanfriendly>=4.7 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (4.16.1)\n",
      "Requirement not upgraded as not directly required: azure-cli-nspkg>=2.0.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (3.0.3)\n",
      "Requirement not upgraded as not directly required: argcomplete>=1.8.0 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (1.9.4)\n",
      "Requirement not upgraded as not directly required: adal>=1.0.2 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (1.1.0)\n",
      "Requirement not upgraded as not directly required: azure-cli-telemetry in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (1.0.0)\n",
      "Requirement not upgraded as not directly required: applicationinsights in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azureml-telemetry==1.0.2.*->azureml-train-core==1.0.2.*->azureml-train==1.0.2.*->azureml-sdk) (0.11.6)\n",
      "Requirement not upgraded as not directly required: pycparser in /data/anaconda/envs/py36/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.7->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.2.*->azureml-sdk) (2.18)\n",
      "Requirement not upgraded as not directly required: oauthlib>=0.6.2 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==1.0.2.*->azureml-sdk) (2.1.0)\n",
      "Requirement not upgraded as not directly required: pynacl>=1.0.1 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (1.2.1)\n",
      "Requirement not upgraded as not directly required: bcrypt>=3.1.3 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (3.1.4)\n",
      "Requirement not upgraded as not directly required: portalocker==1.2.1 in /data/anaconda/envs/py36/lib/python3.6/site-packages (from azure-cli-telemetry->azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-sdk) (1.2.1)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mazureml-contrib-brainwave 0.1.56 requires tensorflow>=1.6, which is not installed.\u001b[0m\n",
      "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-widgets 0.1.74 has requirement azureml-core==0.1.74.*, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-widgets 0.1.74 has requirement azureml-pipeline==0.1.74.*, but you'll have azureml-pipeline 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-widgets 0.1.74 has requirement azureml-telemetry==0.1.74.*, but you'll have azureml-telemetry 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-widgets 0.1.74 has requirement azureml-train-core==0.1.74.*, but you'll have azureml-train-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-automl 0.1.59 has requirement azureml-core==0.1.59, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-train-automl 0.1.59 has requirement azureml-telemetry==0.1.59, but you'll have azureml-telemetry 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-tensorboard 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-server 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-run 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazureml-contrib-brainwave 0.1.56 has requirement azureml-core==0.1.56, but you'll have azureml-core 1.0.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.2.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling Keras-2.2.4:\n",
      "      Successfully uninstalled Keras-2.2.4\n",
      "Successfully installed keras-2.1.5\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#This is only one time run to install the required python libraries on this virtual machine\n",
    "!{sys.executable} -m pip install h5py\n",
    "#Upgrade Pandas (we need version 0.23+), the latest AzureML SDK, and the keras version the model was made on\n",
    "!{sys.executable} -m pip install -U pandas azureml-sdk keras==2.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# import the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.5\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER = \"MSFT\"\n",
    "\n",
    "SHARE_ROOT = \"./stockdemo-model/\"\n",
    "\n",
    "# the model in h5 format\n",
    "LSTM_MODEL = TICKER +'-modellstm.h5'\n",
    "LSTM_MODEL_PATH = SHARE_ROOT + LSTM_MODEL\n",
    "\n",
    "# the min_max values dictionary\n",
    "MIN_MAX_DICT = TICKER +'-min_max.pkl'\n",
    "MIN_MAX_DICT_PATH = SHARE_ROOT + MIN_MAX_DICT\n",
    "\n",
    "# path to pickle test df\n",
    "TEST_DATA_PATH = SHARE_ROOT + TICKER + '-test_score_df.pkl'\n",
    "\n",
    "# Azure Container Service (ACI) Name\n",
    "ACI_SERVICE_NAME = TICKER + '-aciservice'\n",
    "\n",
    "# Azure Kubernetes Service (AKS) Name\n",
    "AKS_SERVICE_NAME = TICKER + '-aksservice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the test data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataframe loaded\n"
     ]
    }
   ],
   "source": [
    "with open(TEST_DATA_PATH, 'rb') as handle:\n",
    "    test_df = pickle.load(handle)\n",
    "    print(\"Test Dataframe loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-14</th>\n",
       "      <td>95.120</td>\n",
       "      <td>95.410</td>\n",
       "      <td>93.50</td>\n",
       "      <td>93.85</td>\n",
       "      <td>31576898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-15</th>\n",
       "      <td>93.530</td>\n",
       "      <td>94.580</td>\n",
       "      <td>92.83</td>\n",
       "      <td>94.18</td>\n",
       "      <td>26279014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16</th>\n",
       "      <td>94.680</td>\n",
       "      <td>95.380</td>\n",
       "      <td>93.92</td>\n",
       "      <td>94.60</td>\n",
       "      <td>47329521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-19</th>\n",
       "      <td>93.740</td>\n",
       "      <td>93.900</td>\n",
       "      <td>92.11</td>\n",
       "      <td>92.89</td>\n",
       "      <td>31752589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-20</th>\n",
       "      <td>93.050</td>\n",
       "      <td>93.770</td>\n",
       "      <td>93.00</td>\n",
       "      <td>93.13</td>\n",
       "      <td>21787780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-21</th>\n",
       "      <td>92.930</td>\n",
       "      <td>94.050</td>\n",
       "      <td>92.21</td>\n",
       "      <td>92.48</td>\n",
       "      <td>23753263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>91.265</td>\n",
       "      <td>91.750</td>\n",
       "      <td>89.66</td>\n",
       "      <td>89.79</td>\n",
       "      <td>37578166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>89.500</td>\n",
       "      <td>90.460</td>\n",
       "      <td>87.08</td>\n",
       "      <td>87.18</td>\n",
       "      <td>42159397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>90.610</td>\n",
       "      <td>94.000</td>\n",
       "      <td>90.40</td>\n",
       "      <td>93.78</td>\n",
       "      <td>55031149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>94.940</td>\n",
       "      <td>95.139</td>\n",
       "      <td>88.51</td>\n",
       "      <td>89.47</td>\n",
       "      <td>53704562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High    Low  Close      Volume\n",
       "Date                                                \n",
       "2018-03-14  95.120  95.410  93.50  93.85  31576898.0\n",
       "2018-03-15  93.530  94.580  92.83  94.18  26279014.0\n",
       "2018-03-16  94.680  95.380  93.92  94.60  47329521.0\n",
       "2018-03-19  93.740  93.900  92.11  92.89  31752589.0\n",
       "2018-03-20  93.050  93.770  93.00  93.13  21787780.0\n",
       "2018-03-21  92.930  94.050  92.21  92.48  23753263.0\n",
       "2018-03-22  91.265  91.750  89.66  89.79  37578166.0\n",
       "2018-03-23  89.500  90.460  87.08  87.18  42159397.0\n",
       "2018-03-26  90.610  94.000  90.40  93.78  55031149.0\n",
       "2018-03-27  94.940  95.139  88.51  89.47  53704562.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to recreate the feature engineering (creating the sequence features) just as we did in the model building notebook.\n",
    "\n",
    "We will do this within the webservice so that the service can take the raw  data, and return a scored result predicting the value (label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test init() and run() functions to read from the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web service requires two functions, an init() function that will initialize the web service by loading the model into the service, and a run() function that will engineer the features to match the model call structure, and score that data set. We create the functions in here for testing and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    # read in the model file\n",
    "    global model\n",
    "    global min_max_dict_list\n",
    "    \n",
    "    # load model\n",
    "    model = load_model(LSTM_MODEL_PATH)\n",
    "    print(\"Model Loaded\")\n",
    "    \n",
    "    # Load Min Max list values\n",
    "    with open(MIN_MAX_DICT_PATH, 'rb') as handle:\n",
    "        min_max_dict_list = pickle.load(handle)\n",
    "        print(\"Min_max List loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = pd.read_json(data, orient='records')\n",
    "        data_n = data.copy()\n",
    "        \n",
    "        # Normalize data\n",
    "        min_dict = min_max_dict_list[0]\n",
    "        max_dict = min_max_dict_list[1]\n",
    "        for feature_name in data_n.columns:\n",
    "            data_n[feature_name] = (data[feature_name] - min_dict[feature_name]) / (max_dict[feature_name] - min_dict[feature_name])\n",
    "        \n",
    "        # Create sequences\n",
    "        data_n = data_n.reindex(sorted(data_n.columns), axis=1) # To make sure columns are always with same order\n",
    "        data = data_n.values \n",
    "        seq_len = 10\n",
    "        result = []\n",
    "        for index in range(len(data) - seq_len + 1):\n",
    "            result.append(data[index: index + seq_len])\n",
    "\n",
    "        result = np.array(result)\n",
    "        print(result.shape)\n",
    "        \n",
    "        pred = model.predict(result)\n",
    "        print(pred)\n",
    "        \n",
    "        # de-normalize the target\n",
    "        pred = pred * (max_dict[\"Close\"] - min_dict[\"Close\"]) + min_dict[\"Close\"]\n",
    "        \n",
    "        # Send results\n",
    "        pred = pred.tolist()\n",
    "        return json.dumps({\"result\": pred})\n",
    "\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The webservice test requires an initialize of the webservice, then send the entire scoring data set into the model. We expect to get 1  prediction for each input in the scoring data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": \"[{\\\\\"Open\\\\\":95.12,\\\\\"High\\\\\":95.41,\\\\\"Low\\\\\":93.5,\\\\\"Close\\\\\":93.85,\\\\\"Volume\\\\\":31576898.0},{\\\\\"Open\\\\\":93.53,\\\\\"High\\\\\":94.58,\\\\\"Low\\\\\":92.83,\\\\\"Close\\\\\":94.18,\\\\\"Volume\\\\\":26279014.0},{\\\\\"Open\\\\\":94.68,\\\\\"High\\\\\":95.38,\\\\\"Low\\\\\":93.92,\\\\\"Close\\\\\":94.6,\\\\\"Volume\\\\\":47329521.0},{\\\\\"Open\\\\\":93.74,\\\\\"High\\\\\":93.9,\\\\\"Low\\\\\":92.11,\\\\\"Close\\\\\":92.89,\\\\\"Volume\\\\\":31752589.0},{\\\\\"Open\\\\\":93.05,\\\\\"High\\\\\":93.77,\\\\\"Low\\\\\":93.0,\\\\\"Close\\\\\":93.13,\\\\\"Volume\\\\\":21787780.0},{\\\\\"Open\\\\\":92.93,\\\\\"High\\\\\":94.05,\\\\\"Low\\\\\":92.21,\\\\\"Close\\\\\":92.48,\\\\\"Volume\\\\\":23753263.0},{\\\\\"Open\\\\\":91.265,\\\\\"High\\\\\":91.75,\\\\\"Low\\\\\":89.66,\\\\\"Close\\\\\":89.79,\\\\\"Volume\\\\\":37578166.0},{\\\\\"Open\\\\\":89.5,\\\\\"High\\\\\":90.46,\\\\\"Low\\\\\":87.08,\\\\\"Close\\\\\":87.18,\\\\\"Volume\\\\\":42159397.0},{\\\\\"Open\\\\\":90.61,\\\\\"High\\\\\":94.0,\\\\\"Low\\\\\":90.4,\\\\\"Close\\\\\":93.78,\\\\\"Volume\\\\\":55031149.0},{\\\\\"Open\\\\\":94.94,\\\\\"High\\\\\":95.139,\\\\\"Low\\\\\":88.51,\\\\\"Close\\\\\":89.47,\\\\\"Volume\\\\\":53704562.0}]\"}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps({\"data\": test_df.to_json(orient='records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n",
      "Min_max List loaded\n",
      "(1, 10, 5)\n",
      "[[0.7146112]]\n",
      "{\"result\": [[87.61872100830078]]}\n"
     ]
    }
   ],
   "source": [
    "init()\n",
    "pred=run(json.dumps({\"data\": test_df.to_json(orient='records')}))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we persist the assets we have created for use in operationalization. The conda dependencies are defined in this YAML file. This will be used to tell the webservice server which python packages are required to run this web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/myenv.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}myenv.yml\n",
    "name: myenv\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.5.2\n",
    "  - pip:\n",
    "    - keras\n",
    "    - tensorflow\n",
    "    - h5py\n",
    "    # Required packages for AzureML execution, history, and data preparation.\n",
    "    - azureml-sdk\n",
    "    - azureml-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score.py file is python code defining the web service operation. It includes both the init() and run() functions defined earlier imports the required libraries. These should be nearly identical to the previous defined versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}score.py\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "TICKER = \"MSFT\"\n",
    "LSTM_MODEL = TICKER +'-modellstm.h5'\n",
    "MIN_MAX_DICT = TICKER +'-min_max.pkl'\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global min_max_dict_list\n",
    "    \n",
    "    # load model\n",
    "    model_path = Model.get_model_path(model_name = LSTM_MODEL)\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Load Min Max list values\n",
    "    model_path = Model.get_model_path(model_name = MIN_MAX_DICT)\n",
    "    with open(model_path, 'rb') as handle:\n",
    "        min_max_dict_list = pickle.load(handle)\n",
    "        print(\"Min_max List loaded\")\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = pd.read_json(data, orient='records')\n",
    "        data_n = data.copy()\n",
    "        \n",
    "        # Normalize data\n",
    "        min_dict = min_max_dict_list[0]\n",
    "        max_dict = min_max_dict_list[1]\n",
    "        for feature_name in data.columns:\n",
    "            data_n[feature_name] = (data[feature_name] - min_dict[feature_name]) / (max_dict[feature_name] - min_dict[feature_name])\n",
    "        \n",
    "        # Create sequences\n",
    "        data_n = data_n.reindex(sorted(data_n.columns), axis=1) # To make sure columns are always with same order\n",
    "        data = data_n.values \n",
    "        seq_len = 10\n",
    "        result = []\n",
    "        for index in range(len(data) - seq_len + 1):\n",
    "            result.append(data[index: index + seq_len])\n",
    "\n",
    "        result = np.array(result)\n",
    "        print(result.shape)\n",
    "        \n",
    "        pred = model.predict(result)\n",
    "        print(pred)\n",
    "        \n",
    "        # De-normalize the target\n",
    "        pred = pred * (max_dict[\"Close\"] - min_dict[\"Close\"]) + min_dict[\"Close\"]\n",
    "        \n",
    "        # Send results\n",
    "        pred = pred.tolist()\n",
    "        return json.dumps({\"result\": pred})\n",
    "\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also include a python file test_service.py which can test the web service you create. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a web service out of the scoring script\n",
    "\n",
    "Let's now see how we can create a scoring web service from the above model. We are going to be using the Preview of the Azure ML Python SDK.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Optional - If not on DSVM or Azure notebooks - Download and install Azure ML Python SDK\n",
    "In a terminal window, type the following commands.\n",
    "  \n",
    "```shell\n",
    "# create a new conda environment with Python 3.6, numpy and cython\n",
    "$ conda create -n myenv Python=3.6 cython numpy\n",
    "\n",
    "# Activate the conde environment\n",
    "$ source activate myenv\n",
    "\n",
    "# check pip is pointing to the right pip path\n",
    "(myenv) $ pip --version\n",
    "# you should see a path that includes the name of the conda environment (myenv) such as:\n",
    "# <user-home-dir>/miniconda3/envs/myenv/lib/python3.6/site-packages (python 3.6)\n",
    "\n",
    "# install azure-cli\n",
    "(myenv) $ pip install azure-cli\n",
    "\n",
    "# install or update azureml meta-package\n",
    "(myenv) $ pip install azureml-sdk[notebooks]\n",
    "\n",
    "\n",
    "# add myenv as a new Jupyter Kernel\n",
    "(myenv) $ python -m ipykernel install --user --name myenv --display-name \"myenv\"\n",
    "\n",
    "# Now change the kernel on this notebook to myenv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Register the new RP (Azure Resource Provider), if never used before\n",
    "You also must register the new RP in your subscription:\n",
    "```shell\n",
    "$ az login\n",
    "$ az account set -s \"<subscription_id>\"\n",
    "\n",
    "# register the new RP\n",
    "$ az provider register -n Microsoft.MachineLearningServices\n",
    "\n",
    "# check the registration status\n",
    "$ az provider show -n Microsoft.MachineLearningServices\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configure the AML Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Workspace class and create the AML Workspace\n",
    "\n",
    "from azureml.core import Workspace\n",
    "subscription_id = \"<YOUR SUBSCRIPTION ID>\"\n",
    "resource_group = \"meetups_aml_rg\"\n",
    "workspace_name = \"meetups_aml_workspace\"\n",
    "workspace_region = 'eastus2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourceGroups/meetups_aml_rg/providers/Microsoft.MachineLearningServices/workspaces/meetups_aml_workspace',\n",
       " 'name': 'meetups_aml_workspace',\n",
       " 'location': 'eastus2',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'workspaceid': '10c56d30-1664-4e88-a549-5961139a4274',\n",
       " 'description': '',\n",
       " 'friendlyName': 'meetups_aml_workspace',\n",
       " 'creationTime': '2018-12-10T06:04:55.6272021+00:00',\n",
       " 'containerRegistry': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourcegroups/meetups_aml_rg/providers/microsoft.containerregistry/registries/meetupsaacrcuzwspcs',\n",
       " 'keyVault': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourcegroups/meetups_aml_rg/providers/microsoft.keyvault/vaults/meetupsakeyvaultzjqsylpe',\n",
       " 'applicationInsights': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourcegroups/meetups_aml_rg/providers/microsoft.insights/components/meetupsainsightsyjuidkum',\n",
       " 'identityPrincipalId': '3ad7d5d4-9306-4415-bab4-bd9c40f5930d',\n",
       " 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'storageAccount': '/subscriptions/b1395605-1fe9-4af4-b3ff-82a4725a3791/resourcegroups/meetups_aml_rg/providers/microsoft.storage/storageaccounts/meetupsastorageadldjqqp'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only one time\n",
    "ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region)\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: /data/home/sshuser/notebooks/Meetups-Data-AI-DFW/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "#You can validate that you have access to the specified workspace and write a configuration file \n",
    "#to the default configuration location, ./aml_config/config.json\n",
    "\n",
    "ws = Workspace(workspace_name = workspace_name,\n",
    "               subscription_id = subscription_id,\n",
    "               resource_group = resource_group)\n",
    "\n",
    "# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/sshuser/notebooks/Meetups-Data-AI-DFW/aml_config/config.json\n",
      "meetups_aml_workspace\n",
      "meetups_aml_rg\n",
      "eastus2\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuratio from ./aml_config/config.json file\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model MSFT-modellstm.h5\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = LSTM_MODEL_PATH,\n",
    "                       model_name = LSTM_MODEL,\n",
    "                       tags = {'ticker': TICKER, 'type': \"lstm\", 'target': \"Close\"},\n",
    "                       description = \"LSTM regression model to predict \"+ TICKER +\" Close price\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model MSFT-min_max.pkl\n"
     ]
    }
   ],
   "source": [
    "min_max_dict_model = Model.register(model_path = MIN_MAX_DICT_PATH,\n",
    "                       model_name = MIN_MAX_DICT,\n",
    "                       tags = {'ticker': TICKER, 'type': \"pickleDict\", 'target': \"Close\"},\n",
    "                       description = \"MIN_MAX dictionary use to normalization of \"+ TICKER +\" stock data\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT-min_max.pkl\tMIN_MAX dictionary use to normalization of MSFT stock data\t1\n"
     ]
    }
   ],
   "source": [
    "print(min_max_dict_model.name, min_max_dict_model.description, min_max_dict_model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore the registered models within your workspace and query by tag. Models are versioned. If you call the register_model command many times with same model name, you will get multiple versions of the model with increasing version numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: MSFT-min_max.pkl \tVersion: 1\n",
      "Name: MSFT-modellstm.h5 \tVersion: 1\n"
     ]
    }
   ],
   "source": [
    "for key,value in ws.models.items():\n",
    "    print(\"Name:\", key,\"\\tVersion:\", value.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that following command can take few minutes.<br>\n",
    "Note that the score.py and the conda yml file must be in the same directory than this notebook.<br>\n",
    "You can add tags and descriptions to images. Also, an image can contain multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./stockdemo-model/score.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./stockdemo-model/myenv.yml ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.....................................\n",
      "SucceededImage creation operation finished for image msft.image:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  description = \"Image with \"+ TICKER + \"regression LSTM model\",\n",
    "                                                  tags = {'ticker': TICKER, 'type': \"lstm\", 'target': \"Close\"}\n",
    "                                                 )\n",
    "\n",
    "image = ContainerImage.create(name = TICKER.lower() + \".image\",\n",
    "                              # this is the model object\n",
    "                              models = [model, min_max_dict_model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm score.py myenv.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msft.image:1 msft.image(v.1 [Succeeded]) stored at meetupsaacrcuzwspcs.azurecr.io/msft.image:1 with build log https://eastus2ice.blob.core.windows.net/logs/meetupsaacrcuzwspcs_a6209ea2e50249599ee1f2f76664075b.txt?se=2019-01-09T06%3A12%3A09Z&sr=b&sp=r&sv=2017-04-17&sig=r2ZPiiZb7gOIGAZkTFHRSsKcasS14FD1/%2B6OfYA3CzM%3D\n"
     ]
    }
   ],
   "source": [
    "for i in image.list(workspace = ws, image_name=TICKER.lower() + \".image\"):\n",
    "    print('{} {}(v.{} [{}]) stored at {} with build log {}'.format(i.id, i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deploy image as web service on Azure Container Instance (ACI)\n",
    "\n",
    "Note that the service creation can take few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = ACI_SERVICE_NAME.lower()\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 4, \n",
    "                                               tags = {'ticker': TICKER, 'type': \"lstm\", 'target': \"Close\"}, \n",
    "                                               description = \"ACI Service to predict \"+ TICKER +\" Close price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see if we have an ACI web service already running in the workspace\n",
    "aci_service = \"\"\n",
    "for aci in AciWebservice.list(workspace=ws):\n",
    "    if (aci.compute_type == \"ACI\"):\n",
    "        if (aci.name == aci_service_name): \n",
    "            aci_service = aci\n",
    "            print(\"Existing ACI Service name:\", aci_service.name)\n",
    "        else:\n",
    "            print(\"No service by the name of **\"+aci_service_name+\"** exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 393 ms, sys: 41 ms, total: 434 ms\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We update the image if service exists or create a new service if doesnt exist\n",
    "if (aci_service == \"\"):\n",
    "    aci_service = AciWebservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "    aci_service.wait_for_deployment(True)\n",
    "    print(aci_service.state)\n",
    "else:\n",
    "    aci_service.update(image=image)\n",
    "    aci_service.wait_for_deployment(True)\n",
    "    print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msft-aciservice\n",
      "Healthy\n",
      "eastus\n",
      "msft.image:1\n",
      "http://23.96.126.64:80/score\n",
      "ACI Service to predict MSFT Close price\n",
      "{'ticker': 'MSFT', 'type': 'lstm', 'target': 'Close'}\n"
     ]
    }
   ],
   "source": [
    "print(aci_service.name)\n",
    "print(aci_service.state)\n",
    "print(aci_service.location)\n",
    "print(aci_service.image_id)\n",
    "print(aci_service.scoring_uri)\n",
    "print(aci_service.description)\n",
    "print(aci_service.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this command to debug if Service failed\n",
    "#aci_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test ACI web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web service hosted in ACI: http://23.96.126.64:80/score\n"
     ]
    }
   ],
   "source": [
    "print('web service hosted in ACI:', aci_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [[87.61872863769531]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_sample = json.dumps({\"data\": test_df.to_json(orient='records')})\n",
    "\n",
    "prediction = aci_service.run(input_data = test_sample)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we manually create the json url payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"{\\\\\"result\\\\\": [[87.61872863769531]]}\"'\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# The URL will need to be editted after service create.\n",
    "url_aci = aci_service.scoring_uri\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "body = json.dumps({\"data\": test_df.to_json(orient='records')})\n",
    "\n",
    "#Send Request to ACI service and print response\n",
    "req_aci = urllib.request.Request(url_aci, str.encode(body), headers) \n",
    "print(urllib.request.urlopen(req_aci).read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can run the test_service.py on the terminal and should yield the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Deploy image as web service on Azure Kubernetes  (AKS)\n",
    "You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import AksWebservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see first if we have a compute cluster available in the workspace\n",
    "aks_name = 'meetup-aks'\n",
    "aks_target = \"\"\n",
    "aks_service_name = AKS_SERVICE_NAME.lower() \n",
    "aks_service = \"\"\n",
    "\n",
    "for aks in AksCompute.list(ws):\n",
    "    if (aks.name == aks_name): \n",
    "        aks_target = aks\n",
    "        print(\"Existing Cluster name: \", aks_target.name)\n",
    "\n",
    "for akss in AksWebservice.list(ws):\n",
    "      if (akss.name == aks_service_name): \n",
    "        aks_service = akss\n",
    "        print(\"Existing AKS Web Service name: \", aks_service.name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running.................\n",
      "SucceededAKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 414 ms, sys: 47 ms, total: 461 ms\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if (aks_service == \"\"):\n",
    "    # Set the AKS Cluster configuration\n",
    "    prov_config = AksCompute.provisioning_configuration(agent_count=6, vm_size=\"Standard_DS2_v2\", ssl_cname=None, \n",
    "                                                        ssl_cert_pem_file=None, ssl_key_pem_file=None, \n",
    "                                                        location=\"EastUs2\")\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                     name = aks_name, \n",
    "                                     provisioning_configuration = prov_config)\n",
    "\n",
    "    aks_target.wait_for_completion(show_output = True)\n",
    "    print(aks_target.provisioning_errors)\n",
    "\n",
    "    #Set the web service configuration\n",
    "    aks_config = AksWebservice.deploy_configuration(autoscale_enabled=True, autoscale_min_replicas=3, \n",
    "                                                autoscale_max_replicas=10, autoscale_refresh_seconds=None, \n",
    "                                                autoscale_target_utilization=80, collect_model_data=None, \n",
    "                                                cpu_cores=None, memory_gb=None, enable_app_insights=True, \n",
    "                                                scoring_timeout_ms=None, replica_max_concurrent_requests=None, \n",
    "                                                num_replicas=None, primary_key=None, secondary_key=None, \n",
    "                                                tags = {'ticker': TICKER, 'type': \"lstm\", 'target': \"Close\"}, \n",
    "                                                description=\"AKS Service\")\n",
    "\n",
    "    # Create the Web Service\n",
    "    aks_service = AksWebservice.deploy_from_image(workspace = ws, \n",
    "                                           name = aks_service_name,\n",
    "                                           image = image,\n",
    "                                           deployment_config = aks_config,\n",
    "                                           deployment_target = aks_target)\n",
    "    \n",
    "    aks_service.wait_for_deployment(show_output = True)\n",
    "    print(aks_service.state)\n",
    "    \n",
    "else:\n",
    "    aks_service.update(image=image)\n",
    "    aks_service.wait_for_deployment(show_output = True)\n",
    "    print(aks_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Optional\n",
    "# # #If you have existing AKS cluster in your Azure subscription, you can attach it to the Workspace.\n",
    "# resource_id = '/subscriptions/'+subscription_id+'/resourcegroups/'+resource_group+'/providers/Microsoft.ContainerService/managedClusters/meetup-aks0cc0670632458d8'\n",
    "\n",
    "# # Attached the existing as compute target\n",
    "# aks_target = AksCompute.attach(workspace=ws, name=aks_name, resource_id=resource_id)\n",
    "# # Wait for the operation to complete\n",
    "# aks_target.wait_for_completion(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: meetup-aks\n",
      "Agent Count: 6\n",
      "VM Size: STANDARD_DS2_V2\n",
      "Location: eastus2\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:\", aks_target.name)\n",
    "print(\"Agent Count:\", aks_target.agent_count)\n",
    "print(\"VM Size:\", aks_target.agent_vm_size)\n",
    "print(\"Location:\", aks_target.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msft-aksservice\n",
      "Healthy\n",
      "msft.image:1\n",
      "http://40.70.46.7/api/v1/service/msft-aksservice/score\n",
      "B4wuo6MBKFfhCndDMkt10pgDKFCcvrX4\n"
     ]
    }
   ],
   "source": [
    "print(aks_service.name)\n",
    "print(aks_service.state)\n",
    "print(aks_service.image_id)\n",
    "print(aks_service.scoring_uri)\n",
    "print(aks_service.get_keys()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Test AKS web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web service hosted in AKS: http://40.70.46.7/api/v1/service/msft-aksservice/score\n"
     ]
    }
   ],
   "source": [
    "print('web service hosted in AKS:', aks_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [[87.61872863769531]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_sample = json.dumps({\"data\": test_df.to_json(orient='records')})\n",
    "\n",
    "prediction = aks_service.run(input_data = test_sample)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we manually create the json url payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"{\\\\\"result\\\\\": [[87.61872863769531]]}\"'\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import requests\n",
    "\n",
    "# The URL will need to be editted after service create.\n",
    "url_aks = aks_service.scoring_uri\n",
    "\n",
    "headers = {'Content-Type':'application/json', \"Authorization\":\"Bearer \"+aks_service.get_keys()[0]}\n",
    "\n",
    "body = json.dumps({\"data\": test_df.to_json(orient='records')})\n",
    "\n",
    "#Send Request to AKS service and print response\n",
    "req_aks = urllib.request.Request(url_aks, str.encode(body), headers) \n",
    "print(urllib.request.urlopen(req_aks).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Delete web services, image and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "aci_service.delete()\n",
    "aks_service.delete()\n",
    "aks_target.delete()\n",
    "image.delete()\n",
    "model.delete()\n",
    "min_max_dict_model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting\n",
      "Deleting\n"
     ]
    }
   ],
   "source": [
    "print(aks_service.state)\n",
    "print(aci_service.state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
