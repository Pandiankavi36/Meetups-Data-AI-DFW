{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Deep Learning for Predictive Maintenance\n\nDeep learning has proven to show superior performance in certain domains such as object recognition and image classification. It has also gained popularity in  domains such as finance where time-series data plays an important role. Predictive Maintenance is also a domain where data is collected over time to monitor the state of an asset with the goal of finding patterns to predict failures which can also benefit from certain deep learning algorithms. Among the deep learning methods, Long Short Term Memory [(LSTM)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) networks are especially appealing to the predictive maintenance domain due to the fact that they are very good at learning from sequences. This fact lends itself to their applications using time series data by making it possible to look back for longer periods of time to detect failure patterns. In this notebook, we build an LSTM network for the data set and scenerio described at [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) to predict remaining useful life of aircraft engines. In summary, the template uses simulated aircraft sensor values to predict when an aircraft engine will fail in the future so that maintenance can be planned in advance. \n\nThis notebook serves as a tutorial for beginners looking to apply deep learning in predictive maintenance domain and uses a simple scenario where only one data source (sensor values) is used to make predictions. In more advanced predictive maintenance scenarios such as in [Predictive Maintenance Modelling Guide](https://gallery.cortanaintelligence.com/Notebook/Predictive-Maintenance-Modelling-Guide-R-Notebook-1), there are many other data sources (i.e. historical maintenance records, error logs, machine and operator features etc.) which may require different types of treatments to be used in the deep learning networks. Since predictive maintenance is not a typical domain for deep learning, its application is an open area of research. \n\nThis notebook uses [keras](https://keras.io/) deep learning library."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Problem Description\nTo predict remaining useful life (or time to failure) of aircraft engines <a href=\"https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan\">[3]</a> based on scenario described at <a href=\"https://github.com/Azure/lstms_for_predictive_maintenance/blob/master/Deep%20Learning%20Basics%20for%20Predictive%20Maintenance.ipynb\">[1]</a> and <a href=\"https://gallery.cortanaintelligence.com/Experiment/Predictive-Maintenance-Step-2A-of-3-train-and-evaluate-regression-models-2\">[2]</a>.\nThe network uses simulated aircraft sensor values to predict when an aircraft engine will fail in the future so that maintenance can be planned in advance.\nThe question to ask is \"Given these aircraft engine operation and failure events history, can we predict when an in-service engine will fail?\"\nWe re-formulate this question into two closely relevant questions and answer them using two different types of machine learning models:\n\n- Binary classification: Is this engine going to fail within w1 cycles? (in this tutorial)\n- Regression models: How many more cycles an in-service engine will last before it fails? (as homework)\n\n## Data\nIn the **Dataset** there are the training, test and ground truth datasets.\nThe training data consists of **multiple multivariate time series** with \"cycle\" as the time unit, together with 21 sensor readings for each cycle.\nEach time series can be assumed as being generated from a different engine of the same type.\nThe testing data has the same data schema as the training data.\nThe only difference is that the data does not indicate when the failure occurs.\nFinally, the ground truth data provides the number of remaining working cycles for the engines in the testing data.\n\n\nYou can find more details about the data at <a href=\"https://github.com/Azure/lstms_for_predictive_maintenance/blob/master/Deep%20Learning%20Basics%20for%20Predictive%20Maintenance.ipynb\">[1]</a> and <a href=\"https://gallery.cortanaintelligence.com/Experiment/Predictive-Maintenance-Step-2A-of-3-train-and-evaluate-regression-models-2\">[2]</a>."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import keras",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Setting seed for reproducability\nnp.random.seed(1234)  \nPYTHONHASHSEED = 0\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Activation\n%matplotlib inline",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Data Ingestion\nIn the following section, we ingest the training, test and ground truth datasets from azure storage. The training data consists of multiple multivariate time series with \"cycle\" as the time unit, together with 21 sensor readings for each cycle. Each time series can be assumed as being generated from a different engine of the same type. The testing data has the same data schema as the training data. The only difference is that the data does not indicate when the failure occurs. Finally, the ground truth data provides the number of remaining working cycles for the engines in the testing data. You can find more details about the type of data used for this notebook at [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import urllib\nimport os\n\nbasedataurl = \"http://azuremlsamples.azureml.net/templatedata/\"\ndatafile = \"PM_train.txt\"\n# Download the file once, and only once.\nif not os.path.isfile(datafile): urllib.request.urlretrieve(basedataurl+datafile, datafile)\n\ndatafile = \"PM_test.txt\"\n# Download the file once, and only once.\nif not os.path.isfile(datafile): urllib.request.urlretrieve(basedataurl+datafile, datafile)\n\ndatafile = \"PM_truth.txt\"\n# Download the file once, and only once.\nif not os.path.isfile(datafile): urllib.request.urlretrieve(basedataurl+datafile, datafile)\n\n",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# read training data \ntrain_df = pd.read_csv('PM_train.txt', sep=\" \", header=None)\ntrain_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\ntrain_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n                     's15', 's16', 's17', 's18', 's19', 's20', 's21']",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# read test data\ntest_df = pd.read_csv('PM_test.txt', sep=\" \", header=None)\ntest_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\ntest_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n                     's15', 's16', 's17', 's18', 's19', 's20', 's21']",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# read ground truth data\ntruth_df = pd.read_csv('PM_truth.txt', sep=\" \", header=None)\ntruth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_df = train_df.sort_values(['id','cycle'])\ndisplay(train_df.head())",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s12</th>\n      <th>s13</th>\n      <th>s14</th>\n      <th>s15</th>\n      <th>s16</th>\n      <th>s17</th>\n      <th>s18</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.0007</td>\n      <td>-0.0004</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>641.82</td>\n      <td>1589.70</td>\n      <td>1400.60</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>521.66</td>\n      <td>2388.02</td>\n      <td>8138.62</td>\n      <td>8.4195</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.06</td>\n      <td>23.4190</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0019</td>\n      <td>-0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.15</td>\n      <td>1591.82</td>\n      <td>1403.14</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>522.28</td>\n      <td>2388.07</td>\n      <td>8131.49</td>\n      <td>8.4318</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.00</td>\n      <td>23.4236</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.0043</td>\n      <td>0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1587.99</td>\n      <td>1404.20</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>522.42</td>\n      <td>2388.03</td>\n      <td>8133.23</td>\n      <td>8.4178</td>\n      <td>0.03</td>\n      <td>390</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.95</td>\n      <td>23.3442</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0007</td>\n      <td>0.0000</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1582.79</td>\n      <td>1401.87</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>522.86</td>\n      <td>2388.08</td>\n      <td>8133.83</td>\n      <td>8.3682</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.88</td>\n      <td>23.3739</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>-0.0019</td>\n      <td>-0.0002</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.37</td>\n      <td>1582.85</td>\n      <td>1406.22</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>522.19</td>\n      <td>2388.04</td>\n      <td>8133.80</td>\n      <td>8.4294</td>\n      <td>0.03</td>\n      <td>393</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.90</td>\n      <td>23.4044</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>",
            "text/plain": "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n\n      s5   ...        s12      s13      s14     s15   s16  s17   s18    s19  \\\n0  14.62   ...     521.66  2388.02  8138.62  8.4195  0.03  392  2388  100.0   \n1  14.62   ...     522.28  2388.07  8131.49  8.4318  0.03  392  2388  100.0   \n2  14.62   ...     522.42  2388.03  8133.23  8.4178  0.03  390  2388  100.0   \n3  14.62   ...     522.86  2388.08  8133.83  8.3682  0.03  392  2388  100.0   \n4  14.62   ...     522.19  2388.04  8133.80  8.4294  0.03  393  2388  100.0   \n\n     s20      s21  \n0  39.06  23.4190  \n1  39.00  23.4236  \n2  38.95  23.3442  \n3  38.88  23.3739  \n4  38.90  23.4044  \n\n[5 rows x 26 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Preprocessing\nFirst step is to generate labels for the training data which are Remaining Useful Life (RUL), label1 and label2 as was done in the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3). Here, we will only make use of \"label1\" for binary clasification, while trying to answer the question: is a specific engine going to fail within w1 cycles?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Data Labeling - generate column RUL\nrul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\nrul.columns = ['id', 'max']\ntrain_df = train_df.merge(rul, on=['id'], how='left')\ntrain_df['RUL'] = train_df['max'] - train_df['cycle']\ntrain_df.drop('max', axis=1, inplace=True)\ndisplay(train_df.head())",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s13</th>\n      <th>s14</th>\n      <th>s15</th>\n      <th>s16</th>\n      <th>s17</th>\n      <th>s18</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>RUL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.0007</td>\n      <td>-0.0004</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>641.82</td>\n      <td>1589.70</td>\n      <td>1400.60</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.02</td>\n      <td>8138.62</td>\n      <td>8.4195</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.06</td>\n      <td>23.4190</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0019</td>\n      <td>-0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.15</td>\n      <td>1591.82</td>\n      <td>1403.14</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.07</td>\n      <td>8131.49</td>\n      <td>8.4318</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.00</td>\n      <td>23.4236</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.0043</td>\n      <td>0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1587.99</td>\n      <td>1404.20</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.03</td>\n      <td>8133.23</td>\n      <td>8.4178</td>\n      <td>0.03</td>\n      <td>390</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.95</td>\n      <td>23.3442</td>\n      <td>189</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0007</td>\n      <td>0.0000</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1582.79</td>\n      <td>1401.87</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.08</td>\n      <td>8133.83</td>\n      <td>8.3682</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.88</td>\n      <td>23.3739</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>-0.0019</td>\n      <td>-0.0002</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.37</td>\n      <td>1582.85</td>\n      <td>1406.22</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.04</td>\n      <td>8133.80</td>\n      <td>8.4294</td>\n      <td>0.03</td>\n      <td>393</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.90</td>\n      <td>23.4044</td>\n      <td>187</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>",
            "text/plain": "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n\n      s5 ...       s13      s14     s15   s16  s17   s18    s19    s20  \\\n0  14.62 ...   2388.02  8138.62  8.4195  0.03  392  2388  100.0  39.06   \n1  14.62 ...   2388.07  8131.49  8.4318  0.03  392  2388  100.0  39.00   \n2  14.62 ...   2388.03  8133.23  8.4178  0.03  390  2388  100.0  38.95   \n3  14.62 ...   2388.08  8133.83  8.3682  0.03  392  2388  100.0  38.88   \n4  14.62 ...   2388.04  8133.80  8.4294  0.03  393  2388  100.0  38.90   \n\n       s21  RUL  \n0  23.4190  191  \n1  23.4236  190  \n2  23.3442  189  \n3  23.3739  188  \n4  23.4044  187  \n\n[5 rows x 27 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# generate label columns for training data\nw1 = 30\nw0 = 15\ntrain_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\ntrain_df['label2'] = train_df['label1']\ntrain_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\ndisplay(train_df.head())",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s15</th>\n      <th>s16</th>\n      <th>s17</th>\n      <th>s18</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>RUL</th>\n      <th>label1</th>\n      <th>label2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.0007</td>\n      <td>-0.0004</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>641.82</td>\n      <td>1589.70</td>\n      <td>1400.60</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>8.4195</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.06</td>\n      <td>23.4190</td>\n      <td>191</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0019</td>\n      <td>-0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.15</td>\n      <td>1591.82</td>\n      <td>1403.14</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>8.4318</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.00</td>\n      <td>23.4236</td>\n      <td>190</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.0043</td>\n      <td>0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1587.99</td>\n      <td>1404.20</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>8.4178</td>\n      <td>0.03</td>\n      <td>390</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.95</td>\n      <td>23.3442</td>\n      <td>189</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0007</td>\n      <td>0.0000</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1582.79</td>\n      <td>1401.87</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>8.3682</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.88</td>\n      <td>23.3739</td>\n      <td>188</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>-0.0019</td>\n      <td>-0.0002</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.37</td>\n      <td>1582.85</td>\n      <td>1406.22</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>8.4294</td>\n      <td>0.03</td>\n      <td>393</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.90</td>\n      <td>23.4044</td>\n      <td>187</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>",
            "text/plain": "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n\n      s5   ...       s15   s16  s17   s18    s19    s20      s21  RUL  label1  \\\n0  14.62   ...    8.4195  0.03  392  2388  100.0  39.06  23.4190  191       0   \n1  14.62   ...    8.4318  0.03  392  2388  100.0  39.00  23.4236  190       0   \n2  14.62   ...    8.4178  0.03  390  2388  100.0  38.95  23.3442  189       0   \n3  14.62   ...    8.3682  0.03  392  2388  100.0  38.88  23.3739  188       0   \n4  14.62   ...    8.4294  0.03  393  2388  100.0  38.90  23.4044  187       0   \n\n   label2  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  \n\n[5 rows x 29 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) , cycle column is also used for training so we will also include the cycle column. Here, we normalize the columns in the training data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# MinMax normalization\nfrom sklearn.externals import joblib\nscaler_filename = \"scaler.pkl\"\n\ntrain_df['cycle_norm'] = train_df['cycle']\ncols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\nmin_max_scaler = preprocessing.MinMaxScaler()\n\nnorm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n                             columns=cols_normalize, \n                             index=train_df.index)\n\njoblib.dump(min_max_scaler, scaler_filename) \n\njoin_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\ntrain_df = join_df.reindex(columns = train_df.columns)\ntrain_df.head()",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n  return self.partial_fit(X, y)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s16</th>\n      <th>s17</th>\n      <th>s18</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>RUL</th>\n      <th>label1</th>\n      <th>label2</th>\n      <th>cycle_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.459770</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.183735</td>\n      <td>0.406802</td>\n      <td>0.309757</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.713178</td>\n      <td>0.724662</td>\n      <td>191</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.609195</td>\n      <td>0.250000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.283133</td>\n      <td>0.453019</td>\n      <td>0.352633</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.731014</td>\n      <td>190</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00277</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.252874</td>\n      <td>0.750000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.343373</td>\n      <td>0.369523</td>\n      <td>0.370527</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.627907</td>\n      <td>0.621375</td>\n      <td>189</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00554</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.540230</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.343373</td>\n      <td>0.256159</td>\n      <td>0.331195</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.573643</td>\n      <td>0.662386</td>\n      <td>188</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00831</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.390805</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.349398</td>\n      <td>0.257467</td>\n      <td>0.404625</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.416667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.589147</td>\n      <td>0.704502</td>\n      <td>187</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.01108</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>",
            "text/plain": "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n0   1      1  0.459770  0.166667       0.0  0.0  0.183735  0.406802  0.309757   \n1   1      2  0.609195  0.250000       0.0  0.0  0.283133  0.453019  0.352633   \n2   1      3  0.252874  0.750000       0.0  0.0  0.343373  0.369523  0.370527   \n3   1      4  0.540230  0.500000       0.0  0.0  0.343373  0.256159  0.331195   \n4   1      5  0.390805  0.333333       0.0  0.0  0.349398  0.257467  0.404625   \n\n    s5     ...      s16       s17  s18  s19       s20       s21  RUL  label1  \\\n0  0.0     ...      0.0  0.333333  0.0  0.0  0.713178  0.724662  191       0   \n1  0.0     ...      0.0  0.333333  0.0  0.0  0.666667  0.731014  190       0   \n2  0.0     ...      0.0  0.166667  0.0  0.0  0.627907  0.621375  189       0   \n3  0.0     ...      0.0  0.333333  0.0  0.0  0.573643  0.662386  188       0   \n4  0.0     ...      0.0  0.416667  0.0  0.0  0.589147  0.704502  187       0   \n\n   label2  cycle_norm  \n0       0     0.00000  \n1       0     0.00277  \n2       0     0.00554  \n3       0     0.00831  \n4       0     0.01108  \n\n[5 rows x 30 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cols_normalize",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "Index(['cycle_norm', 's1', 's10', 's11', 's12', 's13', 's14', 's15', 's16',\n       's17', 's18', 's19', 's2', 's20', 's21', 's3', 's4', 's5', 's6', 's7',\n       's8', 's9', 'setting1', 'setting2', 'setting3'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Next, we prepare the test data. We first normalize the test data using the parameters from the MinMax normalization applied on the training data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "min_max_scaler = joblib.load(scaler_filename) \n    \ntest_df['cycle_norm'] = test_df['cycle']\nnorm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n                            columns=cols_normalize, \n                            index=test_df.index)\ntest_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\ntest_df = test_join_df.reindex(columns = test_df.columns)\ntest_df = test_df.reset_index(drop=True)\ntest_df_original = test_df.copy()\ntest_df.head()\n",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s13</th>\n      <th>s14</th>\n      <th>s15</th>\n      <th>s16</th>\n      <th>s17</th>\n      <th>s18</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>cycle_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.632184</td>\n      <td>0.750000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.545181</td>\n      <td>0.310661</td>\n      <td>0.269413</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.220588</td>\n      <td>0.132160</td>\n      <td>0.308965</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.558140</td>\n      <td>0.661834</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.344828</td>\n      <td>0.250000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.150602</td>\n      <td>0.379551</td>\n      <td>0.222316</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.264706</td>\n      <td>0.204768</td>\n      <td>0.213159</td>\n      <td>0.0</td>\n      <td>0.416667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.682171</td>\n      <td>0.686827</td>\n      <td>0.00277</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.517241</td>\n      <td>0.583333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.376506</td>\n      <td>0.346632</td>\n      <td>0.322248</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.220588</td>\n      <td>0.155640</td>\n      <td>0.458638</td>\n      <td>0.0</td>\n      <td>0.416667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.728682</td>\n      <td>0.721348</td>\n      <td>0.00554</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.741379</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.370482</td>\n      <td>0.285154</td>\n      <td>0.408001</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.250000</td>\n      <td>0.170090</td>\n      <td>0.257022</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.662110</td>\n      <td>0.00831</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.580460</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.391566</td>\n      <td>0.352082</td>\n      <td>0.332039</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.220588</td>\n      <td>0.152751</td>\n      <td>0.300885</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.658915</td>\n      <td>0.716377</td>\n      <td>0.01108</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>",
            "text/plain": "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n\n    s5     ...           s13       s14       s15  s16       s17  s18  s19  \\\n0  0.0     ...      0.220588  0.132160  0.308965  0.0  0.333333  0.0  0.0   \n1  0.0     ...      0.264706  0.204768  0.213159  0.0  0.416667  0.0  0.0   \n2  0.0     ...      0.220588  0.155640  0.458638  0.0  0.416667  0.0  0.0   \n3  0.0     ...      0.250000  0.170090  0.257022  0.0  0.250000  0.0  0.0   \n4  0.0     ...      0.220588  0.152751  0.300885  0.0  0.166667  0.0  0.0   \n\n        s20       s21  cycle_norm  \n0  0.558140  0.661834     0.00000  \n1  0.682171  0.686827     0.00277  \n2  0.728682  0.721348     0.00554  \n3  0.666667  0.662110     0.00831  \n4  0.658915  0.716377     0.01108  \n\n[5 rows x 27 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Next, we use the ground truth dataset to generate labels for the test data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# generate column max for test data\nrul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\nrul.columns = ['id', 'max']\ntruth_df.columns = ['more']\ntruth_df['id'] = truth_df.index + 1\ntruth_df['max'] = rul['max'] + truth_df['more']\ntruth_df.drop('more', axis=1, inplace=True)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# generate RUL for test data\ntest_df = test_df.merge(truth_df, on=['id'], how='left')\ntest_df['RUL'] = test_df['max'] - test_df['cycle']\ntest_df.drop('max', axis=1, inplace=True)\ndisplay(test_df.head())",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s14</th>\n      <th>s15</th>\n      <th>s16</th>\n      <th>s17</th>\n      <th>s18</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>cycle_norm</th>\n      <th>RUL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.632184</td>\n      <td>0.750000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.545181</td>\n      <td>0.310661</td>\n      <td>0.269413</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.132160</td>\n      <td>0.308965</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.558140</td>\n      <td>0.661834</td>\n      <td>0.00000</td>\n      <td>142</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.344828</td>\n      <td>0.250000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.150602</td>\n      <td>0.379551</td>\n      <td>0.222316</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.204768</td>\n      <td>0.213159</td>\n      <td>0.0</td>\n      <td>0.416667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.682171</td>\n      <td>0.686827</td>\n      <td>0.00277</td>\n      <td>141</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.517241</td>\n      <td>0.583333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.376506</td>\n      <td>0.346632</td>\n      <td>0.322248</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.155640</td>\n      <td>0.458638</td>\n      <td>0.0</td>\n      <td>0.416667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.728682</td>\n      <td>0.721348</td>\n      <td>0.00554</td>\n      <td>140</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.741379</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.370482</td>\n      <td>0.285154</td>\n      <td>0.408001</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.170090</td>\n      <td>0.257022</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.662110</td>\n      <td>0.00831</td>\n      <td>139</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.580460</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.391566</td>\n      <td>0.352082</td>\n      <td>0.332039</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.152751</td>\n      <td>0.300885</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.658915</td>\n      <td>0.716377</td>\n      <td>0.01108</td>\n      <td>138</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>",
            "text/plain": "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n\n    s5 ...        s14       s15  s16       s17  s18  s19       s20       s21  \\\n0  0.0 ...   0.132160  0.308965  0.0  0.333333  0.0  0.0  0.558140  0.661834   \n1  0.0 ...   0.204768  0.213159  0.0  0.416667  0.0  0.0  0.682171  0.686827   \n2  0.0 ...   0.155640  0.458638  0.0  0.416667  0.0  0.0  0.728682  0.721348   \n3  0.0 ...   0.170090  0.257022  0.0  0.250000  0.0  0.0  0.666667  0.662110   \n4  0.0 ...   0.152751  0.300885  0.0  0.166667  0.0  0.0  0.658915  0.716377   \n\n   cycle_norm  RUL  \n0     0.00000  142  \n1     0.00277  141  \n2     0.00554  140  \n3     0.00831  139  \n4     0.01108  138  \n\n[5 rows x 28 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# generate label columns w0 and w1 for test data\ntest_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\ntest_df['label2'] = test_df['label1']\ntest_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\ndisplay(test_df.head())",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s16</th>\n      <th>s17</th>\n      <th>s18</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>cycle_norm</th>\n      <th>RUL</th>\n      <th>label1</th>\n      <th>label2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.632184</td>\n      <td>0.750000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.545181</td>\n      <td>0.310661</td>\n      <td>0.269413</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.558140</td>\n      <td>0.661834</td>\n      <td>0.00000</td>\n      <td>142</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.344828</td>\n      <td>0.250000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.150602</td>\n      <td>0.379551</td>\n      <td>0.222316</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.416667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.682171</td>\n      <td>0.686827</td>\n      <td>0.00277</td>\n      <td>141</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.517241</td>\n      <td>0.583333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.376506</td>\n      <td>0.346632</td>\n      <td>0.322248</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.416667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.728682</td>\n      <td>0.721348</td>\n      <td>0.00554</td>\n      <td>140</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.741379</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.370482</td>\n      <td>0.285154</td>\n      <td>0.408001</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.662110</td>\n      <td>0.00831</td>\n      <td>139</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.580460</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.391566</td>\n      <td>0.352082</td>\n      <td>0.332039</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.658915</td>\n      <td>0.716377</td>\n      <td>0.01108</td>\n      <td>138</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>",
            "text/plain": "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n\n    s5   ...    s16       s17  s18  s19       s20       s21  cycle_norm  RUL  \\\n0  0.0   ...    0.0  0.333333  0.0  0.0  0.558140  0.661834     0.00000  142   \n1  0.0   ...    0.0  0.416667  0.0  0.0  0.682171  0.686827     0.00277  141   \n2  0.0   ...    0.0  0.416667  0.0  0.0  0.728682  0.721348     0.00554  140   \n3  0.0   ...    0.0  0.250000  0.0  0.0  0.666667  0.662110     0.00831  139   \n4  0.0   ...    0.0  0.166667  0.0  0.0  0.658915  0.716377     0.01108  138   \n\n   label1  label2  \n0       0       0  \n1       0       0  \n2       0       0  \n3       0       0  \n4       0       0  \n\n[5 rows x 30 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the rest of the notebook, we train an LSTM network that we will compare to the results in [Predictive Maintenance Template Step 2B of 3](https://gallery.cortanaintelligence.com/Experiment/Predictive-Maintenance-Step-2B-of-3-train-and-evaluate-binary-classification-models-2) where a series of machine learning models are used to train and evaluate the binary classification model that uses column \"label1\" as the label."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Modelling\n\nThe traditional predictive maintenance machine learning models are based on feature engineering which is manual construction of right features using domain expertise and similar methods. This usually makes these models hard to reuse since feature engineering is specific to the problem scenario and the available data which varies from one business to the other. Perhaps the most attractive part of applying deep learning in the predictive maintenance domain is the fact that these networks can automatically extract the right features from the data, eliminating the need for manual feature engineering.\n\nWhen using LSTMs in the time-series domain, one important parameter to pick is the sequence length which is the window for LSTMs to look back. This may be viewed as similar to picking window_size = 5 cycles for calculating the rolling features in the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) which are rolling mean and rolling standard deviation for 21 sensor values. The idea of using LSTMs is to let the model extract abstract features out of the sequence of sensor values in the window rather than engineering those manually. The expectation is that if there is a pattern in these sensor values within the window prior to failure, the pattern should be encoded by the LSTM.\n\nOne critical advantage of LSTMs is their ability to remember from long-term sequences (window sizes) which is hard to achieve by traditional feature engineering. For example, computing rolling averages over a window size of 50 cycles may lead to loss of information due to smoothing and abstracting of values over such a long period, instead, using all 50 values as input may provide better results. While feature engineering over large window sizes may not make sense, LSTMs are able to use larger window sizes and use all the information in the window as input. Below, we illustrate the approach."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml\nimport azureml.core",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "SUBSCRIPTION_ID = '<ENTER HERE YOUR AZURE SUBSCRIPTION>'\nWORKSPACE_NAME = 'jptr_predictive_maintenance_ws'\nRESOURCE_GROUP = 'jptr_predictive_maintenance_rg'\nWORKSPACE_REGION = 'westus2'",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\n\n# Check core SDK version number\nprint(\"SDK version:\", azureml.core.VERSION)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK version: 1.0.33\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\n\n# Check core SDK version number\nprint(\"SDK version:\", azureml.core.VERSION)\n\nws = Workspace.create(name = WORKSPACE_NAME,\n                      subscription_id = SUBSCRIPTION_ID,\n                      resource_group = RESOURCE_GROUP, \n                      location = WORKSPACE_REGION,\n                      exist_ok=True)\n",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK version: 1.0.33\nPerforming interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FYPGPSLLU to authenticate.\nInteractive authentication successfully completed.\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "UserWarning: The resource group doesn't exist or was not provided. AzureML SDK is creating a resource group=jptr_predictive_maintenance_rg in location=westus2 using subscription=b81e8c4c-2584-4aa7-8b10-bd1099cf015d.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Deploying KeyVault with name jptrpredkeyvaultebe8583d.\nDeploying StorageAccount with name jptrpredstorage42356bd6e.\nDeploying AppInsights with name jptrpredinsights87770a54.\nDeployed AppInsights with name jptrpredinsights87770a54.\nDeployed StorageAccount with name jptrpredstorage42356bd6e.\nDeployed KeyVault with name jptrpredkeyvaultebe8583d.\nDeploying Workspace with name jptr_predictive_maintenance_ws.\nDeployed Workspace with name jptr_predictive_maintenance_ws.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Save the workspace config\nws.write_config()\n\n# Reconnect to the workspace (if you're not already signed in, you'll be prompted to authenticate with a code as before)\nws = Workspace.from_config()",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%sh\npwd",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/library\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### We Start the experiment and tracking the RUN"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.run import Run\nfrom azureml.core.experiment import Experiment\nimport os\n\nmodel_name = \"predictivemodel.h5\"\nmodel_dbfs = os.path.join(\"/home/nbuser/library/\", model_name)\nrun_history_name = 'predictive-maintenance-local'\n\n# start a training run by defining an experiment\nmyexperiment = Experiment(ws, \"Predictive_Maintenance\")\n",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%sh\nls",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Good Deploy Predictive Maintenance.ipynb\nPM_test.txt\nPM_train.txt\nPM_truth.txt\nREADME.md\nscaler.pkl\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "[Keras LSTM](https://keras.io/layers/recurrent/) layers expect an input in the shape of a numpy array of 3 dimensions (samples, time steps, features) where samples is the number of training sequences, time steps is the look back window or sequence length and features is the number of features of each sequence at each time step."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# function to reshape features into (samples, time steps, features) \ndef gen_sequence(id_df, seq_length, seq_cols):\n    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n    we can use shorter ones \"\"\"\n    data_array = id_df[seq_cols].values\n    num_elements = data_array.shape[0]\n    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n        yield data_array[start:stop, :]\n        \n# function to generate labels\ndef gen_labels(id_df, seq_length, label):\n    data_array = id_df[label].values\n    num_elements = data_array.shape[0]\n    return data_array[seq_length:num_elements, :]\n  \ndef Build_Network(lstm_1, lstm_2, dropout, epochs, sequence_length, nb_features, nb_out, save_weights_filepath ):\n    model = Sequential()\n\n    model.add(LSTM(\n             input_shape=(sequence_length, nb_features),\n             units=lstm_1,\n             return_sequences=True))\n    model.add(Dropout(dropout))\n\n    model.add(LSTM(\n              units=lstm_2,\n              return_sequences=False))\n    model.add(Dropout(dropout))\n\n    model.add(Dense(units=nb_out, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    #print(model.summary())\n    \n    history = model.fit(seq_array, label_array, epochs=epochs, batch_size=200, validation_split=0.05, verbose=0,\n              callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto'),\n                           keras.callbacks.ModelCheckpoint(save_weights_filepath, \n                                                         monitor='val_acc', \n                                                         verbose=0, save_best_only=True, mode='max')])\n    \n    model.load_weights(save_weights_filepath)\n    \n    return model, history\n",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# pick the feature columns \nsensor_cols = ['s' + str(i) for i in range(1,22)]\nsequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\nsequence_cols.extend(sensor_cols)",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nroot_run = myexperiment.start_logging()\n\n# pick a large window size of 50 cycles\nsequence_lengths = [10,25,50,70]\nLSTM_1 = [50,100,150]\nLSTM_2 = [20,50,100]\nDROPOUT = [0.1,0.2,0.5]\nEPOCHS = [10,20,40,50]\n\nsave_weights_filepath = \"best-weights.h5\" \nLSTM_1 = 100\nLSTM_2 = 50\nDROPOUT = 0.2\nEPOCHS = 10\n\n\ni = 0\nfor sequence_length in sequence_lengths:\n  \n    with root_run.child_run(\"seq-length-\" + str(sequence_length)) as run:\n      \n        print(\"Runing Child:\", i )\n        print(\"Using sequence_length=\", sequence_length)\n        i = i + 1\n        # generator for the sequences\n        seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n                   for id in train_df['id'].unique())\n\n        # generate sequences and convert to numpy array\n        seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n        seq_array.shape\n\n        # generate labels\n        label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['label1']) \n                     for id in train_df['id'].unique()]\n        label_array = np.concatenate(label_gen).astype(np.float32)\n        label_array.shape\n\n        #### LSTM NETWORK #####\n        nb_features = seq_array.shape[2]\n        nb_out = label_array.shape[1]\n\n        model, history = Build_Network(LSTM_1, LSTM_2, DROPOUT, EPOCHS, sequence_length, nb_features, nb_out, save_weights_filepath )\n\n        # training metrics\n        scores = model.evaluate(seq_array, label_array, verbose=0, batch_size=200)\n        print('Accurracy: {}'.format(scores[1]))\n\n        # make predictions and compute confusion matrix\n        y_pred = model.predict_classes(seq_array,verbose=1, batch_size=200)\n        y_true = label_array\n        print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n        cm = confusion_matrix(y_true, y_pred)\n        print(cm)\n\n        # compute precision and recall on Training data\n        precision = precision_score(y_true, y_pred)\n        recall = recall_score(y_true, y_pred)\n        print( 'training_precision = ', precision, '\\n', 'training_recall = ', recall)\n\n        # Transforming Test Set\n        seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] \n                           for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n\n        seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n        seq_array_test_last.shape\n\n        y_mask = [len(test_df[test_df['id']==id]) >= sequence_length for id in test_df['id'].unique()]\n\n        label_array_test_last = test_df.groupby('id')['label1'].nth(-1)[y_mask].values\n        label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n        label_array_test_last.shape\n\n        print(seq_array_test_last.shape)\n        print(label_array_test_last.shape)\n\n        # test metrics\n        scores_test = model.evaluate(seq_array_test_last, label_array_test_last, verbose=0)\n        print('Accurracy: {}'.format(scores_test[1]))\n\n        # make predictions and compute confusion matrix\n        y_pred_test = model.predict_classes(seq_array_test_last)\n        y_true_test = label_array_test_last\n        print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n        cm = confusion_matrix(y_true_test, y_pred_test)\n        print(cm)\n\n        # compute precision and recall\n        precision_test = precision_score(y_true_test, y_pred_test)\n        recall_test = recall_score(y_true_test, y_pred_test)\n        f1_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n        print( 'Test Precision: ', precision_test, '\\n', 'Test Recall: ', recall_test,'\\n', 'F1-score:', f1_test )\n\n        #Save model on this child_run to Azure ML Experiment\n        model.save(model_name)\n        run.upload_file(\"outputs/\"+model_name, model_name)        \n        \n        # Log Model design variables\n        run.log(\"sequence_length\", sequence_length)\n        run.log(\"Epochs\",EPOCHS)\n        run.log(\"LSTM_1\", LSTM_1)\n        run.log(\"LSTM_2\", LSTM_2)\n        run.log(\"DROPOUT\", DROPOUT)\n        #Result Metrics\n        run.log(\"Test_Precision\", precision_test)\n        run.log(\"Test_Recall\", recall_test)\n        run.log(\"Test_F1Score\", f1_test)\n        \n        \n             \n# Declare run completed\nroot_run.complete()\nroot_run_id = root_run.id\nprint (\"run id:\", root_run.id)",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Runing Child: 0\nUsing sequence_length= 10\nAccurracy: 0.9635780205589871\n19631/19631 [==============================] - 4s 211us/step\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n[[16283   248]\n [  467  2633]]\ntraining_precision =  0.9139187782020132 \n training_recall =  0.8493548387096774\n(100, 10, 25)\n(100, 1)\nAccurracy: 0.93\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n[[74  1]\n [ 6 19]]\nTest Precision:  0.95 \n Test Recall:  0.76 \n F1-score: 0.8444444444444444\nRuning Child: 1\nUsing sequence_length= 25\nAccurracy: 0.974243016120951\n18131/18131 [==============================] - 7s 381us/step\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n[[14891   140]\n [  327  2773]]\ntraining_precision =  0.9519395811877789 \n training_recall =  0.8945161290322581\n(100, 25, 25)\n(100, 1)\nAccurracy: 0.97\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n[[74  1]\n [ 2 23]]\nTest Precision:  0.9583333333333334 \n Test Recall:  0.92 \n F1-score: 0.9387755102040817\nRuning Child: 2\nUsing sequence_length= 50\nAccurracy: 0.9739620028328555\n15631/15631 [==============================] - 11s 699us/step\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n[[12198   333]\n [   74  3026]]\ntraining_precision =  0.9008633521881513 \n training_recall =  0.9761290322580645\n(93, 50, 25)\n(93, 1)\nAccurracy: 0.9677419425338827\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n[[66  2]\n [ 1 24]]\nTest Precision:  0.9230769230769231 \n Test Recall:  0.96 \n F1-score: 0.9411764705882353\nRuning Child: 3\nUsing sequence_length= 70\nAccurracy: 0.9812192843758119\n13631/13631 [==============================] - 15s 1ms/step\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n[[10368   163]\n [   93  3007]]\ntraining_precision =  0.9485804416403786 \n training_recall =  0.97\n(86, 70, 25)\n(86, 1)\nAccurracy: 0.9651162860005401\nConfusion matrix\n- x-axis is true labels.\n- y-axis is predicted labels\n[[59  2]\n [ 1 24]]\nTest Precision:  0.9230769230769231 \n Test Recall:  0.96 \n F1-score: 0.9411764705882353\nrun id: eadd738e-d798-46ae-9342-9446e1985357\nCPU times: user 31min 50s, sys: 6min 3s, total: 37min 53s\nWall time: 22min 11s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Get metrics from Azure ML Experiment"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "metrics = root_run.get_metrics(recursive=True)\nmetrics",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "{'23cc3166-fe96-4d0a-81bc-cb3a3849fcb7': {'Test_F1Score': 0.8444444444444444,\n  'Test_Recall': 0.76,\n  'Test_Precision': 0.95,\n  'DROPOUT': 0.2,\n  'LSTM_2': 50,\n  'LSTM_1': 100,\n  'Epochs': 10,\n  'sequence_length': 10},\n '30bed365-f281-4673-8937-b86f819a26bd': {'Test_F1Score': 0.9387755102040817,\n  'Test_Recall': 0.92,\n  'Test_Precision': 0.9583333333333334,\n  'DROPOUT': 0.2,\n  'LSTM_2': 50,\n  'LSTM_1': 100,\n  'Epochs': 10,\n  'sequence_length': 25},\n '7982050f-ed3a-40a9-9f5c-a4c4c6b6156c': {'Test_F1Score': 0.9411764705882353,\n  'Test_Recall': 0.96,\n  'Test_Precision': 0.9230769230769231,\n  'DROPOUT': 0.2,\n  'LSTM_2': 50,\n  'LSTM_1': 100,\n  'Epochs': 10,\n  'sequence_length': 50},\n '56bb3a41-17bb-43a9-8d2c-2d806a3d4063': {'Test_F1Score': 0.9411764705882353,\n  'Test_Recall': 0.96,\n  'Test_Precision': 0.9230769230769231,\n  'DROPOUT': 0.2,\n  'LSTM_2': 50,\n  'LSTM_1': 100,\n  'Epochs': 10,\n  'sequence_length': 70}}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Load all run metrics from run history into a dictionary object.\nchild_runs = {}\n\nfor r in root_run.get_children():\n    child_runs[r.id] = r",
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run_id = max(metrics, key = lambda k: metrics[k]['Test_F1Score'])\nbest_run = child_runs[best_run_id]\nprint('Best run is:', best_run_id)\nprint('Test_F1Score:', metrics[best_run_id]['Test_F1Score'])\nprint('Test_Precision:', metrics[best_run_id]['Test_Precision'])\nprint('Test_Recall:', metrics[best_run_id]['Test_Recall'])\nprint(\"sequence_length=\", metrics[best_run_id]['sequence_length'])",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Best run is: 7982050f-ed3a-40a9-9f5c-a4c4c6b6156c\nTest_F1Score: 0.9411764705882353\nTest_Precision: 0.9230769230769231\nTest_Recall: 0.96\nsequence_length= 50\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Register best model and scaler as a MODELS in Azure ML Service Workspace"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Register the Keras model directly from RUN object\n#azmodelname = model_name.split(\".\")[0]\n#azmodel = best_run.register_model(azmodelname, model_path=\"/outputs/\"+model_name, tags={\"F1Score\":metrics[best_run_id]['Test_F1Score'], \"sequence_length\":metrics[best_run_id]['sequence_length']} )",
      "execution_count": 42,
      "outputs": [
        {
          "metadata": {},
          "output_type": "display_data",
          "data": {
            "text/html": "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#azmodelname",
      "execution_count": 43,
      "outputs": [
        {
          "metadata": {},
          "output_type": "display_data",
          "data": {
            "text/html": "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Predictive_Maintenance</td><td>7982050f-ed3a-40a9-9f5c-a4c4c6b6156c</td><td></td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/b81e8c4c-2584-4aa7-8b10-bd1099cf015d/resourceGroups/jptr_predictive_maintenance_rg/providers/Microsoft.MachineLearningServices/workspaces/jptr_predictive_maintenance_ws/experiments/Predictive_Maintenance/runs/7982050f-ed3a-40a9-9f5c-a4c4c6b6156c\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: Predictive_Maintenance,\nId: 7982050f-ed3a-40a9-9f5c-a4c4c6b6156c,\nType: None,\nStatus: Completed)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Register the Min Max model from local file\n\nfrom azureml.core.model import Model\nazmodelminmax = Model.register(model_path = scaler_filename, # this points to a local file\n                       model_name = scaler_filename, # this is the name the model is registered as, am using same name for both path and name.                 \n                       description = \"Scikit MINMAX scaler for Predictve Maintance model\",\n                       workspace = ws)\n\nprint(azmodelminmax.name, azmodelminmax.description, azmodelminmax.version)",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Registering model scaler.pkl\nscaler.pkl Scikit MINMAX scaler for Predictve Maintance model 1\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Find the best run\nbest_run.get_file_names()",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "['outputs/predictivemodel.h5']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_model_name = 'best_run_dnld_predictivemodel.h5'",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run.download_file(name='outputs/predictivemodel.h5', output_file_path='best_run_dnld_predictivemodel.h5')",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "azmodelbestmodel = Model.register(model_path = 'best_run_dnld_predictivemodel.h5',\n                       model_name = 'best_run_dnld_predictivemodel.h5',\n                       tags = {'type': \"lstm\", 'target': \"ATA_CODE\"},\n                       description = \"LSTM model for predictive maintenance\",\n                       workspace = ws)",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Registering model best_run_dnld_predictivemodel.h5\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Deployment of Model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.externals import joblib\nimport json\nfrom keras.models import load_model\n\ndef init():\n    # read in the model file\n    global model\n    global min_max_scaler\n    \n    # load model\n    model = load_model(best_model_name)\n    print(\"Model Loaded\")\n        \n    # And now to load...\n    min_max_scaler = joblib.load(scaler_filename) \n    print(\"Scaler Loaded\")\n",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def run(input_json):\n    try:\n        data = json.loads(input_json)['data']\n        data = pd.read_json(data, orient='records')\n        \n        # Normalize data\n        cols_normalize = data.columns.difference(['id','cycle'])\n        print(cols_normalize)\n        data['cycle_norm'] = data['cycle']\n        norm_data = pd.DataFrame(min_max_scaler.transform(data[cols_normalize]), \n                                    columns=cols_normalize, \n                                    index=data.index)\n        data_join_df = data[data.columns.difference(cols_normalize)].join(norm_data)\n        data = data_join_df.reindex(columns = data.columns)\n        data = data.reset_index(drop=True)\n        data.head()\n        \n        # pick the feature columns \n        sensor_cols = ['s' + str(i) for i in range(1,22)]\n        sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n        sequence_cols.extend(sensor_cols)\n        \n        # sequence_length\n        sequence_length = 50\n        \n        # Transforming Input Set\n        seq_array_test_last = [data[data['id']==id][sequence_cols].values[-sequence_length:] \n                           for id in data['id'].unique() if len(data[data['id']==id]) >= sequence_length]\n\n        seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n        seq_array_test_last.shape\n\n        y_mask = [len(data[data['id']==id]) >= sequence_length for id in data['id'].unique()]\n\n        print(seq_array_test_last.shape)\n        \n        # make predictions and compute confusion matrix\n        y_pred_test = model.predict_classes(seq_array_test_last)\n      \n        # Send results\n        pred = y_pred_test.tolist()\n        return json.dumps({\"result\": pred})\n    except Exception as e:\n        result = str(e)\n        return json.dumps({\"error\": result})",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "init()",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Model Loaded\nScaler Loaded\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run(json.dumps({\"data\": test_df_original.to_json(orient='records')}))",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Index(['cycle_norm', 's1', 's10', 's11', 's12', 's13', 's14', 's15', 's16',\n       's17', 's18', 's19', 's2', 's20', 's21', 's3', 's4', 's5', 's6', 's7',\n       's8', 's9', 'setting1', 'setting2', 'setting3'],\n      dtype='object')\n(93, 50, 25)\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "'{\"result\": [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]}'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "MODEL_NAME = 'best_run_dnld_predictivemodel.h5'",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#%%writefile score_script.py\nscore_script = \"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.externals import joblib\nimport json\nfrom keras.models import load_model\nfrom azureml.core.model import Model\n\ndef init():\n    # read in the model file\n    global model\n    global min_max_scaler\n    \n    # load model\n    MODEL_NAME = 'best_run_dnld_predictivemodel.h5' #interpolated\n    model_path = Model.get_model_path(model_name = MODEL_NAME)\n    model = load_model(model_path)\n    print(\"Model Loaded\")\n        \n    # And now to load...\n    model_name = 'scaler.pkl' #interpolated\n    model_path = Model.get_model_path(model_name = model_name)\n    min_max_scaler = joblib.load(model_path) \n    print(\"Scaler Loaded\")\n\n    \ndef run(input_json):\n    try:\n        data = json.loads(input_json)['data']\n        data = pd.read_json(data, orient='records')\n        \n        # Normalize data\n        cols_normalize = data.columns.difference(['id','cycle'])\n        print(cols_normalize)\n        data['cycle_norm'] = data['cycle']\n        norm_data = pd.DataFrame(min_max_scaler.transform(data[cols_normalize]), \n                                    columns=cols_normalize, \n                                    index=data.index)\n        data_join_df = data[data.columns.difference(cols_normalize)].join(norm_data)\n        data = data_join_df.reindex(columns = data.columns)\n        data = data.reset_index(drop=True)\n        data.head()\n        \n        # pick the feature columns \n        sensor_cols = ['s' + str(i) for i in range(1,22)]\n        sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n        sequence_cols.extend(sensor_cols)\n        \n        # sequence_length\n        sequence_length = 50\n        \n        # Transforming Input Set\n        seq_array_test_last = [data[data['id']==id][sequence_cols].values[-sequence_length:] \n                           for id in data['id'].unique() if len(data[data['id']==id]) >= sequence_length]\n\n        seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n        seq_array_test_last.shape\n\n        y_mask = [len(data[data['id']==id]) >= sequence_length for id in data['id'].unique()]\n\n        print(seq_array_test_last.shape)\n        \n        # make predictions and compute confusion matrix\n        y_pred_test = model.predict_classes(seq_array_test_last)\n      \n        # Send results\n        pred = y_pred_test.tolist()\n        return json.dumps({{\"result\": pred}})\n    except Exception as e:\n        result = str(e)\n        return json.dumps({{\"error\": result}})\n    \n\"\"\".format(model_name=MODEL_NAME, scaler_filename=scaler_filename)\n\nexec(score_script)\n\nwith open(\"score_script.py\", \"w\") as file:\n    file.write(score_script)",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%sh \ncat score_script.py",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.externals import joblib\nimport json\nfrom keras.models import load_model\nfrom azureml.core.model import Model\n\ndef init():\n    # read in the model file\n    global model\n    global min_max_scaler\n    \n    # load model\n    MODEL_NAME = 'best_run_dnld_predictivemodel.h5' #interpolated\n    model_path = Model.get_model_path(model_name = MODEL_NAME)\n    model = load_model(model_path)\n    print(\"Model Loaded\")\n        \n    # And now to load...\n    model_name = 'scaler.pkl' #interpolated\n    model_path = Model.get_model_path(model_name = model_name)\n    min_max_scaler = joblib.load(model_path) \n    print(\"Scaler Loaded\")\n\n    \ndef run(input_json):\n    try:\n        data = json.loads(input_json)['data']\n        data = pd.read_json(data, orient='records')\n        \n        # Normalize data\n        cols_normalize = data.columns.difference(['id','cycle'])\n        print(cols_normalize)\n        data['cycle_norm'] = data['cycle']\n        norm_data = pd.DataFrame(min_max_scaler.transform(data[cols_normalize]), \n                                    columns=cols_normalize, \n                                    index=data.index)\n        data_join_df = data[data.columns.difference(cols_normalize)].join(norm_data)\n        data = data_join_df.reindex(columns = data.columns)\n        data = data.reset_index(drop=True)\n        data.head()\n        \n        # pick the feature columns \n        sensor_cols = ['s' + str(i) for i in range(1,22)]\n        sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n        sequence_cols.extend(sensor_cols)\n        \n        # sequence_length\n        sequence_length = 50\n        \n        # Transforming Input Set\n        seq_array_test_last = [data[data['id']==id][sequence_cols].values[-sequence_length:] \n                           for id in data['id'].unique() if len(data[data['id']==id]) >= sequence_length]\n\n        seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n        seq_array_test_last.shape\n\n        y_mask = [len(data[data['id']==id]) >= sequence_length for id in data['id'].unique()]\n\n        print(seq_array_test_last.shape)\n        \n        # make predictions and compute confusion matrix\n        y_pred_test = model.predict_classes(seq_array_test_last)\n      \n        # Send results\n        pred = y_pred_test.tolist()\n        return json.dumps({\"result\": pred})\n    except Exception as e:\n        result = str(e)\n        return json.dumps({\"error\": result})\n    \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create Conda file for the docker image creation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies \n\nmyacienv = CondaDependencies.create(conda_packages=['scikit-learn','numpy','pandas', 'keras', 'tensorflow', 'h5py']) #showing how to add libs as an example - not needed for this model.\n\nwith open(\"mydeployenv.yml\",\"w\") as f:\n    f.write(myacienv.serialize_to_string())",
      "execution_count": 48,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%sh \ncat mydeployenv.yml",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": "# Conda environment specification. The dependencies defined in this file will\r\n# be automatically provisioned for runs with userManagedDependencies=False.\r\n\n# Details about the Conda environment file format:\r\n# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n\nname: project_environment\ndependencies:\n  # The python interpreter version.\r\n  # Currently Azure ML only supports 3.5.2 and later.\r\n- python=3.6.2\n\n- pip:\n  - azureml-defaults\n- scikit-learn\n- numpy\n- pandas\n- keras\n- tensorflow\n- h5py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create ACI config"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#deploy to ACI\nfrom azureml.core.webservice import AciWebservice, Webservice\n\nmyaci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 2, \n    memory_gb = 2, \n    tags = {'name':model_name}, \n    description = 'Predictive Maintenance model')",
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create docker image and web service on the same call"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nservice_name = \"aci4-predictive-maint\"\nruntime = \"python\" \ndriver_file = \"score_script.py\"\nmy_conda_file = \"mydeployenv.yml\"\n\n# image creation\nfrom azureml.core.image import ContainerImage\nimage_config = ContainerImage.image_configuration(execution_script = driver_file, \n                                    runtime = runtime, \n                                    conda_file = my_conda_file)\n\n\n\nimage = ContainerImage.create(name = \"predictivemaintenance\" + \".image\",\n                              # this is the model object\n                              models = [azmodelbestmodel, azmodelminmax],\n                              image_config = image_config,\n                              workspace = ws)\nimage.wait_for_creation(show_output = True)\n\n# # Webservice creation\n# myservice = Webservice.deploy_from_model(\n#   workspace=ws, \n#   name=service_name,\n#   deployment_config = myaci_config,\n#   models = [azmodel, azmodelminmax],\n#   image_config = myimage_config\n#     )\n\n# myservice.wait_for_deployment(show_output=True)",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Creating image\nRunning.......................................................................\nSucceededImage creation operation finished for image predictivemaintenance.image:1, operation \"Succeeded\"\nCPU times: user 2.72 s, sys: 572 ms, total: 3.29 s\nWall time: 6min 34s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Azure Container Service (ACI) Name\nACI_SERVICE_NAME = \"jptrpredmaint\" + '-aciservice'\n\n# Azure Kubernetes Service (AKS) Name\nAKS_SERVICE_NAME = \"predmaint\" + '-aksservice'",
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice\nfrom azureml.core.webservice import Webservice\n\naci_service_name = ACI_SERVICE_NAME.lower()\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                               memory_gb = 4, \n                                               tags = {'type': \"lstm\", 'target': \"maintenance\"}, \n                                               description = \"LSTM model for predictive maintenance\")",
      "execution_count": 61,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Let's see if we have an ACI web service already running in the workspace\naci_service = \"\"\nfor aci in AciWebservice.list(workspace=ws):\n    if (aci.compute_type == \"ACI\"):\n        if (aci.name == aci_service_name): \n            aci_service = aci\n            print(\"Existing ACI Service name:\", aci_service.name)\n        else:\n            print(\"No service by the name of **\"+aci_service_name+\"** exists!\")",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": "No service by the name of **jptrpredmaint-aciservice** exists!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\n# We update the image if service exists or create a new service if doesnt exist\nif (aci_service == \"\"):\n    aci_service = AciWebservice.deploy_from_image(deployment_config = aciconfig,\n                                           image = image,\n                                           name = aci_service_name,\n                                           workspace = ws)\n    aci_service.wait_for_deployment(True)\n    print(aci_service.state)\nelse:\n    aci_service.update(image=image)\n    aci_service.wait_for_deployment(True)\n    print(aci_service.state)",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Creating service\nRunning...................................................................................................................................................................................................................................\nTimedOutACI service creation operation finished, operation \"TimedOut\"\nService creation polling reached terminal state, current service state: Transitioning\nService creation polling reached terminal state, unexpected response received.\nTransitioning\nCPU times: user 7.96 s, sys: 1.74 s, total: 9.7 s\nWall time: 20min 14s\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(aci_service.get_logs())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "##TEST Scoring"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import urllib\nimport requests\nimport json\n\nprint(aci_service.scoring_uri)\n# The URL will need to be editted after service create.\nurl_aci = aci_service.scoring_uri\n\nheaders = {'Content-Type':'application/json'}\n\nbody = json.dumps({\"data\": test_df_original.to_json(orient='records')})\n\n#Send Request to ACI service and print response\nreq_aci = urllib.request.Request(url_aci, str.encode(body), headers) \nprint(urllib.request.urlopen(req_aci).read())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": 72,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "name": "Deep Learning Basics for Predictive Maintenance - Improved",
    "notebookId": 1745626120626465,
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "anaconda-cloud": {}
  },
  "nbformat": 4,
  "nbformat_minor": 1
}